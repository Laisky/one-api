package aws

// Request represents a chat completion request to AWS Bedrock DeepSeek-R1.
//
// This structure defines all the parameters needed to send a chat completion
// request to the DeepSeek-R1 model via AWS Bedrock. DeepSeek-R1 is known for
// its advanced reasoning capabilities and structured response format.
//
// Based on AWS Bedrock DeepSeek-R1 documentation.
type Request struct {
	// Messages contains the conversation history including system, user, and assistant messages.
	// This field is required and must contain at least one message.
	// DeepSeek-R1 processes these messages to generate responses with reasoning content.
	Messages []Message `json:"messages"`

	// MaxTokens specifies the maximum number of tokens to generate in the response.
	// Optional field that helps control response length and API costs.
	// DeepSeek-R1 may use additional tokens for reasoning content.
	MaxTokens int `json:"max_tokens,omitempty"`

	// Temperature controls the randomness of the model's responses.
	// Range: 0.0 to 1.0, where 0.0 is deterministic and 1.0 is most random.
	// Optional field, uses model default if not specified.
	Temperature *float64 `json:"temperature,omitempty"`

	// TopP controls nucleus sampling, limiting the cumulative probability of token choices.
	// Range: 0.0 to 1.0, where lower values make responses more focused.
	// Optional field, uses model default if not specified.
	TopP *float64 `json:"top_p,omitempty"`

	// Stop contains custom strings that will stop generation when encountered.
	// Optional field that allows fine-grained control over response termination.
	// Useful for controlling when DeepSeek-R1 stops generating reasoning or response content.
	Stop []string `json:"stop,omitempty"`
}

// Message represents a single message in the conversation history.
//
// Messages form the core of the chat completion request, containing the back-and-forth
// conversation between different participants. Each message has a specific role that
// determines its purpose and expected content format for DeepSeek-R1 processing.
type Message struct {
	// Role identifies the sender of the message.
	// Valid values: "system" (instructions to guide model behavior),
	// "user" (human input), "assistant" (model response with potential reasoning content).
	Role string `json:"role"`

	// Content contains the text content of the message.
	// Required for system and user messages. For assistant messages, this contains
	// the final response text after reasoning (if any) has been completed.
	Content string `json:"content,omitempty"`
}

// Response represents the complete response from AWS Bedrock DeepSeek-R1.
//
// This structure contains the model's response to a chat completion request,
// including generated text and potentially reasoning content. DeepSeek-R1's responses
// may include both the reasoning process and the final answer in a structured format.
//
// Based on AWS Bedrock DeepSeek-R1 documentation.
type Response struct {
	// Choices contains the possible response options generated by the model.
	// Typically contains a single choice, but the array format maintains
	// compatibility with OpenAI's API structure. Each choice may include reasoning content.
	Choices []Choice `json:"choices"`
}

// Choice represents a single response option from the DeepSeek-R1 model.
//
// Each choice contains the generated content along with metadata about
// why the generation stopped. DeepSeek-R1 choices may include reasoning
// content that shows the model's thought process before arriving at the final answer.
type Choice struct {
	// Index identifies the position of this choice in the choices array.
	// Typically 0 for the first (and usually only) choice.
	Index int `json:"index"`

	// Message contains the actual response content from the assistant.
	// This includes the final response text and may reference reasoning content
	// that was generated during the model's thought process.
	Message ResponseMessage `json:"message"`

	// StopReason indicates why the model stopped generating tokens.
	// Valid values: "stop" (natural completion), "length" (max tokens reached),
	// "end_turn" (model decided to end), "max_tokens" (token limit reached).
	StopReason string `json:"stop_reason"`
}

// ResponseMessage represents the assistant's message in the response.
//
// This structure contains the model's generated content. For DeepSeek-R1,
// this typically includes the final answer after any reasoning process has
// been completed. The role is always "assistant" for response messages.
type ResponseMessage struct {
	// Role identifies the message sender, always "assistant" for responses.
	// This maintains consistency with the conversation message format.
	Role string `json:"role"`

	// Content contains the generated text response from the model.
	// This is the final answer or response after DeepSeek-R1's reasoning
	// process (if any) has been completed.
	Content string `json:"content,omitempty"`
}

// StreamResponse represents a single chunk in a streaming response from DeepSeek-R1.
//
// When using streaming mode, the model sends multiple StreamResponse chunks
// instead of a single complete Response. Each chunk contains incremental
// updates (deltas) that should be accumulated to build the complete response,
// including any reasoning content that DeepSeek-R1 generates.
type StreamResponse struct {
	// Choices contains the streaming choice updates for this chunk.
	// Typically contains a single choice with delta information
	// representing the incremental content since the last chunk.
	Choices []StreamChoice `json:"choices"`
}

// StreamChoice represents a single streaming choice with incremental updates from DeepSeek-R1.
//
// Each streaming choice contains a delta (incremental change) rather than
// the complete content. Clients should accumulate these deltas to build
// the full response content progressively, including reasoning content blocks.
type StreamChoice struct {
	// Index identifies the position of this choice in the choices array.
	// Consistent across all streaming chunks for the same choice.
	Index int `json:"index"`

	// Delta contains the incremental content update for this chunk.
	// This represents new content added since the previous chunk,
	// not the complete accumulated content. May include reasoning content.
	Delta StreamResponseMessage `json:"delta"`

	// StopReason indicates why streaming stopped, present only in the final chunk.
	// Valid values: "stop" (natural completion), "length" (max tokens reached),
	// "end_turn" (model decided to end), "max_tokens" (token limit reached).
	// Empty for intermediate chunks.
	StopReason string `json:"stop_reason,omitempty"`
}

// StreamResponseMessage represents incremental content in a DeepSeek-R1 streaming response.
//
// This structure contains delta (incremental) updates rather than complete content.
// Fields are populated only when they have new content to add. Clients should
// accumulate these deltas to build the complete assistant message, including
// any reasoning content that DeepSeek-R1 provides.
type StreamResponseMessage struct {
	// Role is set only in the first streaming chunk to establish the message role.
	// Typically "assistant" for response messages, empty in subsequent chunks.
	Role string `json:"role,omitempty"`

	// Content contains new text content added in this streaming chunk.
	// Should be appended to previously received content to build the full response.
	// For DeepSeek-R1, this may include incremental reasoning or final answer content.
	Content string `json:"content,omitempty"`
}

// DeepSeekConverseStreamResponse represents a streaming response chunk from AWS Bedrock Converse API for DeepSeek-R1.
//
// This structure is used for AWS Bedrock's Converse API streaming mode, which provides
// a different streaming format compared to the standard chat completions API. DeepSeek-R1's
// Converse API includes special handling for reasoning content blocks.
type DeepSeekConverseStreamResponse struct {
	// MessageStart signals the beginning of a new assistant message.
	// Present in the first chunk of a streaming response to establish the message role.
	MessageStart *DeepSeekMessageStart `json:"messageStart,omitempty"`

	// ContentBlockDelta contains incremental content updates during message generation.
	// Present in intermediate chunks that deliver the actual response content progressively.
	// May include both reasoning content and final answer content from DeepSeek-R1.
	ContentBlockDelta *DeepSeekContentBlockDelta `json:"contentBlockDelta,omitempty"`

	// MessageStop signals the end of message generation with completion reason.
	// Present in the final chunk to indicate why generation stopped.
	MessageStop *DeepSeekMessageStop `json:"messageStop,omitempty"`

	// Metadata provides usage statistics and additional information about the response.
	// May be present in various chunks, typically in the final chunk with complete usage data.
	// Includes reasoning token counts for DeepSeek-R1.
	Metadata *DeepSeekStreamMetadata `json:"metadata,omitempty"`
}

// DeepSeekMessageStart indicates the beginning of a streaming assistant message from DeepSeek-R1.
//
// This event is sent as the first chunk in a Converse API streaming response
// to establish the role of the message being generated.
type DeepSeekMessageStart struct {
	// Role identifies the message sender, typically "assistant" for model responses.
	// Consistent with the conversation message format used throughout the API.
	Role string `json:"role"`
}

// DeepSeekContentBlockDelta contains incremental content updates in Converse API streaming for DeepSeek-R1.
//
// This structure wraps the actual delta content that should be accumulated
// to build the complete response text progressively, including reasoning content.
type DeepSeekContentBlockDelta struct {
	// Delta contains the actual incremental content update.
	// Should be appended to previously received content to build the full response.
	// May contain reasoning content or final answer content from DeepSeek-R1.
	Delta DeepSeekContentDelta `json:"delta"`
}

// DeepSeekContentDelta represents the actual incremental content in a streaming chunk for DeepSeek-R1.
//
// This is the core content structure within Converse API streaming responses,
// containing new content that should be added to the growing response. DeepSeek-R1
// may provide both regular text and reasoning content in structured blocks.
type DeepSeekContentDelta struct {
	// Text contains the new text content added in this streaming chunk.
	// Should be concatenated with previous chunks to build the complete response.
	// This is the final answer content from DeepSeek-R1.
	Text string `json:"text,omitempty"`

	// ReasoningContent contains the reasoning process content from DeepSeek-R1.
	// This unique feature shows the model's internal thought process and reasoning
	// steps before arriving at the final answer in the Text field.
	ReasoningContent *DeepSeekReasoningContent `json:"reasoningContent,omitempty"`
}

// DeepSeekReasoningContent represents the reasoning process content unique to DeepSeek-R1.
//
// This structure captures DeepSeek-R1's internal reasoning process, allowing users
// to understand how the model arrived at its conclusions. This is a key differentiator
// of the DeepSeek-R1 model compared to other language models.
type DeepSeekReasoningContent struct {
	// ReasoningText contains the model's internal reasoning process.
	// This shows the step-by-step thought process that DeepSeek-R1 used
	// to analyze the problem and arrive at its final answer.
	ReasoningText string `json:"reasoningText"`
}

// DeepSeekMessageStop indicates the completion of a streaming message generation from DeepSeek-R1.
//
// This event is sent as the final chunk in a Converse API streaming response
// to signal that message generation has completed and provide the reason for stopping.
type DeepSeekMessageStop struct {
	// StopReason indicates why message generation stopped.
	// Valid values include completion reasons like "stop", "length", "end_turn", or "max_tokens".
	// For DeepSeek-R1, this may also indicate reasoning-specific stop conditions.
	StopReason string `json:"stopReason"`
}

// DeepSeekStreamMetadata contains usage statistics and metadata for DeepSeek-R1 streaming responses.
//
// This structure provides token consumption information and other metadata
// about the streaming response, typically included in the final chunks.
// For DeepSeek-R1, this includes reasoning token counts in addition to standard usage metrics.
type DeepSeekStreamMetadata struct {
	// Usage contains detailed token consumption statistics for the request.
	// Includes input, output, and total token counts for billing and monitoring,
	// with special consideration for DeepSeek-R1's reasoning token usage.
	Usage DeepSeekUsage `json:"usage"`
}

// DeepSeekUsage provides detailed token consumption statistics for DeepSeek-R1.
//
// This structure tracks the number of tokens consumed during request processing,
// essential for billing, quota management, and performance monitoring. DeepSeek-R1
// may consume additional tokens for reasoning content generation.
type DeepSeekUsage struct {
	// InputTokens represents the number of tokens in the input (request).
	// Includes all tokens from messages, system prompts, and context.
	InputTokens int `json:"inputTokens"`

	// OutputTokens represents the number of tokens generated in the response.
	// Includes all tokens in the assistant's response text and reasoning content.
	// For DeepSeek-R1, this may be higher due to reasoning token generation.
	OutputTokens int `json:"outputTokens"`

	// TotalTokens is the sum of InputTokens and OutputTokens.
	// Provides a convenient total for billing and quota calculations.
	TotalTokens int `json:"totalTokens"`
}

// DeepSeekConverseMessage represents a message in AWS Bedrock Converse API format for DeepSeek-R1.
//
// The Converse API uses a different message structure compared to the standard
// chat completions API, with content organized into blocks for enhanced flexibility
// and support for DeepSeek-R1's reasoning content capabilities.
type DeepSeekConverseMessage struct {
	// Role identifies the sender of the message.
	// Valid values: "user" (human input), "assistant" (model response with reasoning).
	// System messages are handled separately via DeepSeekConverseSystemMessage.
	Role string `json:"role"`

	// Content contains the message content organized into structured blocks.
	// For DeepSeek-R1, this may include both text blocks and reasoning content blocks,
	// designed to accommodate the model's unique reasoning capabilities.
	Content []DeepSeekConverseContentBlock `json:"content"`
}

// DeepSeekConverseContentBlock represents a content block within a Converse API message for DeepSeek-R1.
//
// This structure provides a flexible content format that can accommodate different
// types of content. Supports both regular text content and DeepSeek-R1's unique
// reasoning content blocks, designed for extensibility.
type DeepSeekConverseContentBlock struct {
	// Text contains the text content for this content block.
	// This is the primary content type for regular messages and final answers.
	Text string `json:"text,omitempty"`

	// ReasoningContent contains the reasoning process content unique to DeepSeek-R1.
	// This field captures the model's internal thought process and reasoning steps,
	// providing transparency into how the model arrived at its conclusions.
	ReasoningContent *DeepSeekReasoningContent `json:"reasoningContent,omitempty"`
}

// DeepSeekConverseSystemMessage represents system instructions in Converse API format for DeepSeek-R1.
//
// System messages provide instructions and context to the model about how to behave
// during the conversation. In the Converse API, these are handled separately from
// regular user and assistant messages to provide clear guidance for reasoning behavior.
type DeepSeekConverseSystemMessage struct {
	// Text contains the system instruction or prompt.
	// Should provide clear guidance about the model's role, behavior, constraints,
	// and any specific instructions about reasoning display preferences.
	Text string `json:"text"`
}

// DeepSeekConverseInferenceConfig specifies generation parameters for Converse API requests to DeepSeek-R1.
//
// This structure contains all the configurable parameters that control how the model
// generates responses, including length limits, randomness controls, and stopping conditions.
// DeepSeek-R1 may use additional tokens for reasoning content generation.
type DeepSeekConverseInferenceConfig struct {
	// MaxTokens specifies the maximum number of tokens to generate in the response.
	// Required field that helps control response length and API costs.
	// For DeepSeek-R1, consider that reasoning content may require additional tokens.
	MaxTokens int `json:"maxTokens"`

	// Temperature controls the randomness of the model's responses.
	// Range: 0.0 to 1.0, where 0.0 is deterministic and 1.0 is most random.
	// Optional field, uses model default if not specified.
	Temperature *float64 `json:"temperature,omitempty"`

	// TopP controls nucleus sampling, limiting the cumulative probability of token choices.
	// Range: 0.0 to 1.0, where lower values make responses more focused.
	// Optional field, uses model default if not specified.
	TopP *float64 `json:"topP,omitempty"`

	// StopSequences contains custom strings that will stop generation when encountered.
	// Optional field that allows fine-grained control over response termination.
	// Can be used to control when DeepSeek-R1 stops generating reasoning or final content.
	StopSequences []string `json:"stopSequences,omitempty"`
}

// DeepSeekConverseResponse represents the response from Converse API
type DeepSeekConverseResponse struct {
	Message struct {
		Role    string                         `json:"role"`
		Content []DeepSeekConverseContentBlock `json:"content"`
	} `json:"message"`
	StopReason string        `json:"stopReason"`
	Usage      DeepSeekUsage `json:"usage"`
}

// AWS Bedrock DeepSeek response structures matching the official Converse API format
// Content is structured as an array containing text and reasoningContent objects

// DeepSeekBedrockResponse matches AWS Bedrock Converse API format
type DeepSeekBedrockResponse struct {
	ID      string                  `json:"id"`
	Model   string                  `json:"model,omitempty"`
	Object  string                  `json:"object"`
	Created int64                   `json:"created"`
	Choices []DeepSeekBedrockChoice `json:"choices"`
	Usage   DeepSeekUsage           `json:"usage"`
}

// DeepSeekBedrockChoice matches AWS Bedrock choice format
type DeepSeekBedrockChoice struct {
	Index        int                    `json:"index"`
	Message      DeepSeekBedrockMessage `json:"message"`
	FinishReason string                 `json:"finish_reason"`
}

// DeepSeekBedrockMessage matches AWS Bedrock message format with content array
type DeepSeekBedrockMessage struct {
	Role    string                        `json:"role"`
	Content []DeepSeekBedrockContentBlock `json:"content"`
}

// DeepSeekBedrockContentBlock represents content blocks in AWS Bedrock format
type DeepSeekBedrockContentBlock struct {
	Text             *string                   `json:"text,omitempty"`
	ReasoningContent *DeepSeekReasoningContent `json:"reasoningContent,omitempty"`
}

// DeepSeekBedrockStreamResponse for streaming in AWS Bedrock format
type DeepSeekBedrockStreamResponse struct {
	ID      string                        `json:"id"`
	Object  string                        `json:"object"`
	Created int64                         `json:"created"`
	Model   string                        `json:"model"`
	Choices []DeepSeekBedrockStreamChoice `json:"choices"`
	Usage   *DeepSeekUsage                `json:"usage,omitempty"`
}

// DeepSeekBedrockStreamChoice for streaming choices in AWS Bedrock format
type DeepSeekBedrockStreamChoice struct {
	Index        int                          `json:"index"`
	Delta        DeepSeekBedrockStreamMessage `json:"delta"`
	FinishReason *string                      `json:"finish_reason,omitempty"`
}

// DeepSeekBedrockStreamMessage for streaming deltas in AWS Bedrock format
type DeepSeekBedrockStreamMessage struct {
	Role    string                        `json:"role,omitempty"`
	Content []DeepSeekBedrockContentBlock `json:"content,omitempty"`
}
